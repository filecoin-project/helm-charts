# Default values for sentinel-visor
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
replicaCount: 1
logLevel: info
image:
  repo: filecoin/sentinel-visor
  tag: "v0.7.0" # required
  pullPolicy: IfNotPresent

# Custom labels
#labels:
  #name: foo

#
# Global
#

# PostgreSQL options
pgSecret: "" # required
pgDatabase: "" # default `database` key from pgSecret
pgSSLMode: "require"
pgPoolSize: 45
pgAppName: "" # default: "visor_<version>_<host>_<runtime_pid>"

# Debug Options

# sleep container without exiting
debug: false

# prometheus service monitor
prometheusOperatorServiceMonitor: false
prometheusPort: ":9991"

logLevel: info
#logFormat: json
#logLevelNamed: "vm:error,badgerbs:error"

jaeger:
  enabled: false
  host: ""
  port: 6831
  serviceName: "" # default: "visor"
  sampler:
    type: "probabilistic"
    param: 0.0001


allowAutomaticMigration: false

lens: # configure how visor sources its data
  lotusAPI: # backed by a live node's API
    # a lotus-fullnode secret containing jwt read-only token under key 'jwt-ro-privs-token'
    # secret must be in the same namespace
    lotusAPITokenSecret: "" # default: "{{ .Release.Name }}-jwt-secrets"
    # lotus api multiaddr
    lotusAPIMultiaddr: "" # required

#
# Mode-specific
#
watch:
  enabled: true
  confidence: 1
  tasks:
    - blocks
    - messages
    - chaineconomics
    # for least confusion during runtime, pick only one actorStates task. (last one applies)
    - actorstatesraw
    #- actorstatesparsed
    #- actorstatesboth
walk:
  enabled: false
  #from: 0 # default: 0
  #to: 1000 # default: host's MaxUint64
  tasks:
    - blocks
    - messages
    - chaineconomics
    # for least confusion during runtime, pick only one actorStates task. (last one applies)
    - actorstatesraw
    #- actorstatesparsed
    #- actorstatesboth

daemon:
  # Set enabled to true to run visor in daemon mode with its own data store
  enabled: false

  # importSnapshot controls the initialisation of the daemon's data store. When enabled the deployment
  # will start an init container that may call 'visor init' with the url specified. After the init is
  # complete an empty file named '_imported' is placed in the data store directory to signify that
  # the data store has been imported. The import process will be skipped if this file is present.
  # Delete /var/lib/visor/datastore/_imported to force the import to run the next time the pod is
  # restarted. You may want to do this if the daemon has fallen out of sync for a long period of time.
  importSnapshot:
    enabled: false
    url: https://fil-chain-snapshots-fallback.s3.amazonaws.com/mainnet/minimal_finality_stateroots_latest.car

 # volumes enables control over the configuration of attached volumes
  volumes:
    # datastore is the volume used for the daemon's data store. If enabled is false then the data store will
    # be set up on the pod's local storage which will is usally too small.
    # The datastore volume is mounted at /var/lib/visor/datastore
    datastore:
      enabled: true
      size: "1000Gi"
      accessModes:
        - ReadWriteOnce
      storageClassName: "gp2"

  # jobs is a list of jobs to start on the daemon
  # each job has a command and a list of args, for example:
  # - command: watch
  #   args:
  #   - --confidence=10
  #   - --tasks=blocks,messages,chaineconomics
  jobs: []

  # storage is a list of storage configurations that will be added to the visor config
  # and used when starting jobs
  storage:
    postgresql:
    - name: db
      secret: postgresql-secret
      applicationName: visor
      poolSize: 45
      allowUpsert: false
    file:
    - name: csv
      format: CSV
      path: /tmp

  # pubsub settings
  pubsub:
    ipwhitelist: [] # list[string], maps to Pubsub.IPColocationWhitelist in config toml

resources:
  requests:
    cpu: 6000m
    memory: 8Gi
  limits:
    cpu: 8000m
    memory: 16Gi

# A node selector to control placement of pods
nodeSelector: {}

# A set of tolerations to control placement of pods
tolerations: []

# An affinity expression to control placement of pods
affinity: {}
